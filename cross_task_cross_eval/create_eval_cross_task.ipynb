{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy\n",
    "import json\n",
    "import jsonlines\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://webservice\n",
      "Requirement already satisfied: jsonlines in /private/home/akariasai/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from jsonlines) (19.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonlines(file_name):\n",
    "    with jsonlines.open(file_name, 'r') as jsonl_f:\n",
    "        data = [obj for obj in jsonl_f]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gooaq_data = load_jsonlines(\"/checkpoint/akariasai/datasets/gooaq/data/gooaq.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_websites = [\"www.healthline.com\", \"www.mayoclinic.org\", \"www.webmd.com\", \"www.medicalnewstoday.com\", \"www.nhs.uk\", \"www.cdc.gov\", \"medlineplus.gov\"]\n",
    "wiki = \"en.wikipedia.org\"\n",
    "quora = \"www.quora.com\"\n",
    "technical = \"stackoverflow.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "qooaq_med = []\n",
    "qooaq_wiki = []\n",
    "gooaq_quora = []\n",
    "gooqa_technical = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in gooaq_data:\n",
    "    if item[\"answer_type\"] == \"feat_snip\" and item[\"answer_url\"] is not None and \"https://\" in item[\"answer_url\"] :\n",
    "        url = item[\"answer_url\"].split(\"https://\")[1].split(\"/\")[0]\n",
    "        if url in medical_websites:\n",
    "            item[\"url_processed\"] = url\n",
    "            qooaq_med.append(item)\n",
    "        if url == wiki:\n",
    "            item[\"url_processed\"] = url\n",
    "            qooaq_wiki.append(item)\n",
    "        if url == quora:\n",
    "            item[\"url_processed\"] = url\n",
    "            gooaq_quora.append(item)\n",
    "        if url == technical:\n",
    "            item[\"url_processed\"] = url\n",
    "            gooqa_technical.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229287"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qooaq_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149261"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qooaq_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99853"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gooaq_quora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6203"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gooqa_technical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 3821840,\n",
       " 'question': 'where to set jvm arguments in tomcat?',\n",
       " 'short_answer': None,\n",
       " 'answer': '# Most options should go into CATALINA_OPTS. Set it in the JAVA_OPTS variable in [path to tomcat]/bin/catalina.sh. Under windows there is a console where you can set it up or you use the catalina. bat.',\n",
       " 'answer_type': 'feat_snip',\n",
       " 'answer_url': 'https://stackoverflow.com/questions/7738794/add-jvm-options-in-tomcat'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gooqa_technical[4200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 201,\n",
       " 'question': '1 000 characters is how many words?',\n",
       " 'short_answer': None,\n",
       " 'answer': 'A thousand characters should be ≈140 - 150 words, or 143 words precisely.',\n",
       " 'answer_type': 'feat_snip',\n",
       " 'answer_url': 'https://www.quora.com/How-many-words-are-in-1000-or-300-or-500-or-10000-etc-characters#:~:text=three%2C%20for%20example.-,A%20thousand%20characters%20should%20be%20%E2%89%88140,words%2C%20or%20143%20words%20precisely.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gooaq_quora[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 355,\n",
       " 'question': '1 18 scale is how big?',\n",
       " 'short_answer': '11 inches long',\n",
       " 'answer': 'Many 1:18 scale automobiles are over 11 inches long, while 1:18 aircraft may reach over 3 feet in length. 1:18 models often include many intricate details and moving parts not commonly found on models in smaller scales. 1:18 model cars are available as kits, where the enthusiast builds the model from start to finish.',\n",
       " 'answer_type': 'feat_snip',\n",
       " 'answer_url': 'https://en.wikipedia.org/wiki/1:18_scale'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qooaq_wiki[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149261"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qooaq_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://webservice\n",
      "Requirement already satisfied: datasets in /private/home/akariasai/.local/lib/python3.8/site-packages (2.5.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: multiprocess in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (2022.8.2)\n",
      "Requirement already satisfied: aiohttp in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (0.10.1)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from datasets) (20.3)\n",
      "Requirement already satisfied: xxhash in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets) (2.22.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (1.23.3)\n",
      "Requirement already satisfied: responses<0.19 in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in /private/home/akariasai/.local/lib/python3.8/site-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /private/home/akariasai/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /private/home/akariasai/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /private/home/akariasai/.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /private/home/akariasai/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /private/home/akariasai/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /private/home/akariasai/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /private/home/akariasai/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: filelock in /private/home/akariasai/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages/PyYAML-5.1-py3.8-linux-x86_64.egg (from huggingface-hub<1.0.0,>=0.2.0->datasets) (5.1)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /private/home/akariasai/.local/lib/python3.8/site-packages (from responses<0.19->datasets) (1.26.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /private/home/akariasai/.local/lib/python3.8/site-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /private/home/akariasai/.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/private/home/akariasai/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration default\n",
      "Found cached dataset wiki_qa (/private/home/akariasai/.cache/huggingface/datasets/wiki_qa/default/0.1.0/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c)\n",
      "100%|██████████| 3/3 [00:00<00:00, 641.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "wikiqa = datasets.load_dataset(\"wiki_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythons = [item for item in gooqa_technical if \"python\" in item[\"question\"]]\n",
    "Java = [item for item in gooqa_technical if \"java \" in item[\"question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 17253,\n",
       " 'question': '1 is true in python?',\n",
       " 'short_answer': None,\n",
       " 'answer': 'In Python 3. x True and False are keywords and will always be equal to 1 and 0 . ... In numeric contexts (for example when used as the argument to an arithmetic operator), they [False and True] behave like the integers 0 and 1, respectively. So booleans are explicitly considered as integers in Python 2.6 and 3.',\n",
       " 'answer_type': 'feat_snip',\n",
       " 'answer_url': 'https://stackoverflow.com/questions/2764017/is-false-0-and-true-1-an-implementation-detail-or-is-it-guaranteed-by-the#:~:text=In%20Python%203.,equal%20to%201%20and%200%20.&text=In%20numeric%20contexts%20(for%20example,in%20Python%202.6%20and%203.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pythons)\n",
    "pythons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 108545,\n",
       " 'question': 'a fatal error has been detected by the java runtime environment in eclipse?',\n",
       " 'short_answer': None,\n",
       " 'answer': 'so the solution was to do the following in Eclipse: Add the std JRE to \"properties --> java build path --> libraries\" While running, In the \"runconfiguration --> classpath\" remove Android (leaving only std JRE)',\n",
       " 'answer_type': 'feat_snip',\n",
       " 'answer_url': 'https://stackoverflow.com/questions/6017431/a-fatal-error-has-been-detected-by-the-java-runtime-environment-internal-error#:~:text=so%20the%20solution%20was%20to,Android%20(leaving%20only%20std%20JRE)'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Java[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkso_data_python = \"/private/home/akariasai/inst_dpr/preprocessing/linkso_data/topublish/python\"\n",
    "linkso_data_java = \"/private/home/akariasai/inst_dpr/preprocessing/linkso_data/topublish/java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicated_qestions(dir, lang):\n",
    "    duplicated_q_pairs = []\n",
    "    qid2all = pd.read_csv(os.path.join(dir, \"{}_qid2all.txt\".format(lang)), sep=\"\\t\", header=None)\n",
    "    qid2all_dic = {}\n",
    "    for idx, row in qid2all.iterrows():\n",
    "        qid2all_dic[int(row[0])] = {\"title\": row[1], \"body\": row[2]}\n",
    "\n",
    "    cosin =  pd.read_csv(os.path.join(dir, \"{}_cosidf.txt\".format(lang)), sep=\"\\t\")\n",
    "    dup_pair_ids = {}\n",
    "    for idx, row in cosin.iterrows():\n",
    "        if row[\"label\"] == 1:\n",
    "            dup_pair_ids[int(row[\"qid1\"])] = int(row[\"qid2\"])\n",
    "        \n",
    "    test_qs = open(os.path.join(dir, \"{}_test_qid.txt\".format(lang))).read().split(\"\\n\")[:-1]\n",
    "    for q_id in test_qs:\n",
    "        if int(q_id) in dup_pair_ids:\n",
    "            dup_id = dup_pair_ids[int(q_id)]\n",
    "            duplicated_q_pairs.append((qid2all_dic[int(q_id)], qid2all_dic[dup_id]))\n",
    "    return duplicated_q_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkso_dups_python = find_duplicated_qestions(linkso_data_python, \"python\")\n",
    "linkso_dups_java = find_duplicated_qestions(linkso_data_java, \"java\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset code_search_net (/private/home/akariasai/.cache/huggingface/datasets/code_search_net/python/1.0.0/80a244ab541c6b2125350b764dc5c2b715f65f00de7a56107a28915fac173a27)\n",
      "100%|██████████| 3/3 [00:00<00:00, 460.66it/s]\n",
      "Found cached dataset code_search_net (/private/home/akariasai/.cache/huggingface/datasets/code_search_net/java/1.0.0/80a244ab541c6b2125350b764dc5c2b715f65f00de7a56107a28915fac173a27)\n",
      "100%|██████████| 3/3 [00:00<00:00, 464.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# CodeSearchNet\n",
    "python_code_serach_net = datasets.load_dataset(\"code_search_net\", \"python\")\n",
    "java_code_serach_net = datasets.load_dataset(\"code_search_net\", \"java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_short_descs = [item for item in python_code_serach_net[\"test\"] if len(item[\"func_documentation_string\"]) < 300 and len(item[\"func_documentation_string\"]) > 50]\n",
    "java_short_descs = [item for item in java_code_serach_net[\"test\"] if len(item[\"func_documentation_string\"]) < 300 and len(item[\"func_documentation_string\"]) > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16745"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(java_short_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10606"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(python_short_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small helper function to convert a string to a numeric value\n",
      "    if appropriate\n",
      "\n",
      "    :param s: the string to be converted\n",
      "    :type s: str\n",
      "def _convert_to_float_if_possible(s):\n",
      "    \n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n"
     ]
    }
   ],
   "source": [
    "print(python_short_descs[48][\"func_documentation_string\"] )\n",
    "print((python_short_descs[48][\"func_code_string\"].split('\"\"\"')[0] +  python_short_descs[0][\"func_code_string\"].split('\"\"\"')[2]).replace(\"\\n\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_txt2code = []\n",
    "java_txt2code = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Found cached dataset wiki_qa (/private/home/akariasai/.cache/huggingface/datasets/wiki_qa/default/0.1.0/d2d236b5cbdc6fbdab45d168b4d678a002e06ddea3525733a24558150585951c)\n",
      "100%|██████████| 3/3 [00:00<00:00, 700.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# WikiQA \n",
    "wikiqa = datasets.load_dataset(\"wiki_qa\")\n",
    "q_answers = []\n",
    "for item in wikiqa[\"test\"]:\n",
    "    if item[\"label\"] == 1:\n",
    "        q_answers.append({\"question\": item[\"question\"], \"title\": item[\"document_title\"], \"text\": item[\"answer\"]})\n",
    "for item in wikiqa[\"validation\"]:\n",
    "    if item[\"label\"] == 1:\n",
    "        q_answers.append({\"question\": item[\"question\"], \"title\": item[\"document_title\"], \"text\": item[\"answer\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambig QA\n",
    "ambigqa_path = \"/checkpoint/akariasai/datasets/ambignq_light/\"\n",
    "ambigqa_dev_data = load_jsonlines(ambigqa_path + \"dev_light.json\")[0]\n",
    "ambigqa_train_data = load_jsonlines(ambigqa_path + \"train_light.json\")[0]\n",
    "\n",
    "ambig_evals_qq = {}\n",
    "for item in ambigqa_dev_data:\n",
    "    for an in item[\"annotations\"]:\n",
    "        if an[\"type\"] == \"multipleQAs\":\n",
    "            qa_pairs = an[\"qaPairs\"]\n",
    "            for qa in qa_pairs:\n",
    "                ambig_evals_qq.setdefault(item[\"question\"], [])\n",
    "                ambig_evals_qq[item[\"question\"]].append(qa[\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ambig_evals_qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/akariasai/inst_dpr/cross_task_eval\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "! pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"ambig\")\n",
    "os.mkdir(\"wikiqa\")\n",
    "os.mkdir(\"gooqa_med\")\n",
    "os.mkdir(\"gooqa_tech\")\n",
    "os.mkdir(\"pubmedqa\")\n",
    "os.mkdir(\"linkso_py\")\n",
    "os.mkdir(\"linkso_ja\")\n",
    "os.mkdir(\"codesearch_py\")\n",
    "os.mkdir(\"codesearch_ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIKIQA\n",
    "corpus = {}\n",
    "for split in [\"train\", \"test\", \"validation\"]:\n",
    "    for item in wikiqa[split]:\n",
    "        corpus.setdefault(item[\"document_title\"], [])\n",
    "        if item[\"answer\"] not in corpus[item[\"document_title\"]]:\n",
    "            corpus[item[\"document_title\"]].append(item[\"answer\"])\n",
    "    \n",
    "final_corpus = []\n",
    "for title in corpus:\n",
    "    for idx, doc in enumerate(corpus[title]):\n",
    "        final_corpus.append({\"title\": title, \"text\": doc, \"_id\":\"{0}_{1}\".format(title, idx), \"metadata\": {}})\n",
    "\n",
    "final_qrel_data = []\n",
    "final_queries = []\n",
    "for item in wikiqa[\"validation\"]:\n",
    "    question_id = item[\"question_id\"]\n",
    "    question = item[\"question\"]\n",
    "    if item[\"label\"] == 1:\n",
    "        corpus_id = corpus[item[\"document_title\"]].index(item[\"answer\"])\n",
    "        final_queries.append({\"_id\": \"wikiqa_{}\".format(question_id), \"text\": question, \"metadata\": {}})\n",
    "        final_qrel_data.append({\"query-id\": \"wikiqa_{}\".format(question_id), \"corpus-id\": \"{0}_{1}\".format(item[\"document_title\"], corpus_id), \"score\": 1})\n",
    "for item in wikiqa[\"test\"]:\n",
    "    question_id = item[\"question_id\"]\n",
    "    question = item[\"question\"]\n",
    "    if item[\"label\"] == 1:\n",
    "        corpus_id = corpus[item[\"document_title\"]].index(item[\"answer\"])\n",
    "        final_queries.append({\"_id\": \"wikiqa_{}\".format(question_id), \"text\": question, \"metadata\": {}})\n",
    "        final_qrel_data.append({\"query-id\": \"wikiqa_{}\".format(question_id), \"corpus-id\": \"{0}_{1}\".format(item[\"document_title\"], corpus_id), \"score\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query-id': 'wikiqa_Q11', 'corpus-id': 'BMC Software_3', 'score': 1}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_qrel_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'BMC Software', 'text': 'Employing over 6,000, BMC is often credited with pioneering the BSM concept as a way to help better align IT operations with business needs.', '_id': 'BMC Software_3', 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "for item in final_corpus:\n",
    "    if item[\"_id\"] == \"BMC Software_3\":\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "q2dic = {}\n",
    "for item in final_queries:\n",
    "    q2dic[item[\"_id\"]] = item\n",
    "final_queries = list(q2dic.values())\n",
    "\n",
    "with jsonlines.open('wikiqa/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(final_queries)\n",
    "with jsonlines.open('wikiqa/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(final_corpus)\n",
    "with open('wikiqa/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in final_qrel_data:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambig\t       codesearch_py\t\t     gooqa_med\t linkso_ja  pubmedqa\n",
      "codesearch_ja  create_eval_cross_task.ipynb  gooqa_tech  linkso_py  wikiqa\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ambigqa_path = \"/checkpoint/akariasai/datasets/ambignq_light/\"\n",
    "ambigqa_dev_data = load_jsonlines(ambigqa_path + \"dev_light.json\")[0]\n",
    "ambigqa_train_data = load_jsonlines(ambigqa_path + \"train_light.json\")[0]\n",
    "\n",
    "ambig_evals_qq = {}\n",
    "final_queries = []\n",
    "final_corpus = []\n",
    "count = 0\n",
    "for item in ambigqa_train_data:\n",
    "    for an in item[\"annotations\"]:\n",
    "        if an[\"type\"] == \"multipleQAs\":\n",
    "            qa_pairs = an[\"qaPairs\"]\n",
    "            for q in qa_pairs:\n",
    "                final_corpus.append({\"_id\": \"ambig_train_{0}\".format(count), \"text\": q[\"question\"], \"title\": \"\", \"metadata\": {}})\n",
    "                count += 1\n",
    "\n",
    "final_qrels = []\n",
    "count = 0\n",
    "for item in ambigqa_dev_data:\n",
    "    for an in item[\"annotations\"]:\n",
    "        if an[\"type\"] == \"multipleQAs\":\n",
    "            qa_pairs = an[\"qaPairs\"]\n",
    "            for qa in qa_pairs:\n",
    "                target_id = \"ambig_test_{0}\".format(count)\n",
    "                final_corpus.append({\"_id\": \"ambig_test_{0}\".format(count), \"text\": qa[\"question\"], \"title\": \"\" , \"metadata\": {}})\n",
    "                final_queries.append({\"_id\": \"ambig_nq_source_{}\".format(item[\"id\"]), \"text\": item[\"question\"], \"metadata\": {}})\n",
    "                final_qrels.append({\"corpus-id\": \"ambig_test_{0}\".format(count), \"query-id\": \"ambig_nq_source_{}\".format(item[\"id\"]), \"score\": 1})\n",
    "                count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus-id': 'ambig_test_3',\n",
       " 'query-id': 'ambig_nq_source_5780388869788119926',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_qrels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'ambig_nq_source_5780388869788119926',\n",
       " 'text': 'Who is the current chairman of african union commission?',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_queries[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'ambig_test_3', 'text': 'Who is the 4th chairman of african union commission?', 'title': '', 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "for item in final_corpus:\n",
    "    if item[\"_id\"] == \"ambig_test_3\":\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "# save data\n",
    "q2dic = {}\n",
    "for item in final_queries:\n",
    "    q2dic[item[\"_id\"]] = item\n",
    "final_queries = list(q2dic.values())\n",
    "\n",
    "with jsonlines.open('ambig/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(final_queries)\n",
    "with jsonlines.open('ambig/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(final_corpus)\n",
    "with open('ambig/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in final_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GooQA Medical \n",
    "import random\n",
    "random_sampled_qooaq_med = random.sample(qooaq_med, k=2000)\n",
    "\n",
    "full_corpus = []\n",
    "answer2id = {}\n",
    "for idx, item in enumerate(qooaq_med):\n",
    "    full_corpus.append({\"_id\": \"{0}_{1}\".format(item[\"url_processed\"], idx), \"text\": item[\"answer\"], \"title\": \"\", \"metadata\": {}})\n",
    "    answer2id[item[\"answer\"]] = \"{0}_{1}\".format(item[\"url_processed\"], idx)\n",
    "\n",
    "full_queries = []\n",
    "full_qrels = []\n",
    "for item in random_sampled_qooaq_med:\n",
    "    full_queries.append({\"_id\": \"gooaq_med_{}\".format(item[\"id\"]), \"text\": item[\"question\"], \"metadata\": {}})\n",
    "    corpus_id = answer2id[item[\"answer\"]]\n",
    "    full_qrels.append({\"query-id\": \"gooaq_med_{}\".format(item[\"id\"]), \"corpus-id\": corpus_id, \"score\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('gooaq_med/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_queries)\n",
    "with jsonlines.open('gooaq_med/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_corpus)\n",
    "with open('gooaq_med/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in full_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GooAQ technical\n",
    "# GooQA Medical \n",
    "\n",
    "random_sampled_qooaq_tech = random.sample(gooqa_technical, k=1000)\n",
    "\n",
    "full_corpus = []\n",
    "full_queries = []\n",
    "full_qrels = []\n",
    "answer2id = {}\n",
    "\n",
    "for idx, item in enumerate(gooqa_technical):\n",
    "    full_corpus.append({\"_id\": \"{0}_{1}\".format(item[\"url_processed\"], idx), \"text\": item[\"answer\"], \"title\": \"\", \"metadata\": {}})\n",
    "    answer2id[item[\"answer\"]] = \"{0}_{1}\".format(item[\"url_processed\"], idx)\n",
    "\n",
    "\n",
    "for item in random_sampled_qooaq_tech:\n",
    "    full_queries.append({\"_id\": \"gooaq_technical_{}\".format(item[\"id\"]), \"text\": item[\"question\"], \"metadata\": {}})\n",
    "    corpus_id = answer2id[item[\"answer\"]]\n",
    "    full_qrels.append({\"query-id\": \"gooaq_technical_{}\".format(item[\"id\"]), \"corpus-id\": corpus_id, \"score\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 4232,\n",
       " 'question': '1 bit how many characters?',\n",
       " 'short_answer': '256 Characters',\n",
       " 'answer': 'For a boolean values, BIT(1) is pretty common. 2^8 = 256 Characters. A character in binary is a series of 8 ( 0 or 1).',\n",
       " 'answer_type': 'feat_snip',\n",
       " 'answer_url': 'https://stackoverflow.com/questions/21300929/how-many-characters-can-you-store-with-1-byte#:~:text=For%20a%20boolean%20values%2C%20BIT(1)%20is%20pretty%20common.&text=2%5E8%20%3D%20256%20Characters.,8%20(%200%20or%201).',\n",
       " 'url_processed': 'stackoverflow.com'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gooqa_technical[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"gooaq_technical/qrels\")\n",
    "with jsonlines.open('gooaq_technical/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_queries)\n",
    "with jsonlines.open('gooaq_technical/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_corpus)\n",
    "with open('gooaq_technical/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in full_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 6595,\n",
       " 'question': '1 character how many bytes?',\n",
       " 'short_answer': None,\n",
       " 'answer': 'An ASCII character in 8-bit ASCII encoding is 8 bits (1 byte), though it can fit in 7 bits. An ISO-8895-1 character in ISO-8859-1 encoding is 8 bits (1 byte). A Unicode character in UTF-8 encoding is between 8 bits (1 byte) and 32 bits (4 bytes).',\n",
       " 'answer_type': 'feat_snip',\n",
       " 'answer_url': 'https://stackoverflow.com/questions/4850241/how-many-bits-or-bytes-are-there-in-a-character#:~:text=An%20ASCII%20character%20in%208,32%20bits%20(4%20bytes).',\n",
       " 'url_processed': 'stackoverflow.com'}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gooqa_technical[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create codesearch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_short_descs = [item for item in python_code_serach_net[\"test\"] if len(item[\"func_documentation_string\"]) < 300 and len(item[\"func_documentation_string\"]) > 50]\n",
    "java_short_descs = [item for item in java_code_serach_net[\"test\"] if len(item[\"func_documentation_string\"]) < 300 and len(item[\"func_documentation_string\"]) > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "412178it [01:18, 5234.22it/s]\n",
      "23107it [00:04, 4999.98it/s]\n",
      "22176it [00:05, 4180.91it/s]\n"
     ]
    }
   ],
   "source": [
    "full_corpus = []\n",
    "full_queries = []\n",
    "full_qrels = []\n",
    "answer2id = {}\n",
    "\n",
    "for idx, item in tqdm(enumerate(python_code_serach_net[\"train\"])):\n",
    "    doc_id = \"codeserachnet_python_train_{0}_{1}\".format(idx, item[\"func_name\"])\n",
    "    if '\"\"\"' in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split('\"\"\"')[0] +  item[\"func_code_string\"].split('\"\"\"')[2]).replace(\"\\n\\n\", \"\")\n",
    "    elif \"'''\" in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split(\"'''\")[0] +  item[\"func_code_string\"].split(\"'''\")[2]).replace(\"\\n\\n\", \"\")\n",
    "    else:\n",
    "        code = item[\"func_code_string\"]\n",
    "    full_corpus.append({\"_id\": doc_id, \"text\": code, \"metadata\": {}, \"title\": \"\" })\n",
    "    answer2id[code]  =  doc_id\n",
    "\n",
    "for idx, item in tqdm(enumerate(python_code_serach_net[\"validation\"])):\n",
    "    doc_id = \"codeserachnet_python_validation_{0}_{1}\".format(idx, item[\"func_name\"])\n",
    "    if '\"\"\"' in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split('\"\"\"')[0] +  item[\"func_code_string\"].split('\"\"\"')[2]).replace(\"\\n\\n\", \"\")\n",
    "    elif \"'''\" in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split(\"'''\")[0] +  item[\"func_code_string\"].split(\"'''\")[2]).replace(\"\\n\\n\", \"\")\n",
    "    else:\n",
    "        code = item[\"func_code_string\"]\n",
    "    full_corpus.append({\"_id\": doc_id, \"text\": code, \"metadata\": {}, \"title\": \"\" })\n",
    "    answer2id[code]  =  doc_id\n",
    "\n",
    "for idx, item in tqdm(enumerate(python_code_serach_net[\"test\"])):\n",
    "    doc_id = \"codeserachnet_python_test_{0}_{1}\".format(idx, item[\"func_name\"])\n",
    "    if '\"\"\"' in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split('\"\"\"')[0] +  item[\"func_code_string\"].split('\"\"\"')[2]).replace(\"\\n\\n\", \"\")\n",
    "    elif \"'''\" in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split(\"'''\")[0] +  item[\"func_code_string\"].split(\"'''\")[2]).replace(\"\\n\\n\", \"\")\n",
    "    else:\n",
    "        code = item[\"func_code_string\"]\n",
    "    full_corpus.append({\"_id\": doc_id, \"text\": code, \"metadata\": {}, \"title\": \"\" })\n",
    "    answer2id[code]  =  doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457461"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sampled_python_short_descs= random.sample(python_short_descs, k = 1000)\n",
    "random_sampled_ja_short_descs= random.sample(java_short_descs, k = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(random_sampled_python_short_descs):\n",
    "    qid = \"python_codesearch_{}\".format(idx)\n",
    "    \n",
    "    query = item[\"func_documentation_string\"]\n",
    "    if '\"\"\"' in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split('\"\"\"')[0] +  item[\"func_code_string\"].split('\"\"\"')[2]).replace(\"\\n\\n\", \"\")\n",
    "    elif \"'''\" in item[\"func_code_string\"]:\n",
    "        code = (item[\"func_code_string\"].split(\"'''\")[0] +  item[\"func_code_string\"].split(\"'''\")[2]).replace(\"\\n\\n\", \"\")\n",
    "    else:\n",
    "        code = item[\"func_code_string\"]\n",
    "    corpus_id = answer2id[code]\n",
    "    full_queries.append({\"_id\": qid, \"text\": query, \"metadata\": {}})\n",
    "    full_qrels.append({\"corpus-id\": corpus_id, \"query-id\": qid, \"score\": 1})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'python_codesearch_1',\n",
       " 'text': 'Create a Basilisp function, setting meta and supplying a with_meta\\n    method implementation.',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_queries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus-id': 'codeserachnet_python_test_13387__basilisp_fn',\n",
       " 'query-id': 'python_codesearch_1',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qrels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'codeserachnet_python_test_13387__basilisp_fn', 'text': 'def _basilisp_fn(f):\\n    \\n    assert not hasattr(f, \"meta\")\\n    f._basilisp_fn = True\\n    f.meta = None\\n    f.with_meta = partial(_fn_with_meta, f)\\n    return f', 'metadata': {}, 'title': ''}\n"
     ]
    }
   ],
   "source": [
    "for item in full_corpus:\n",
    "    if item[\"_id\"] == 'codeserachnet_python_test_13387__basilisp_fn':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"codesearch_py/qrels\")\n",
    "with jsonlines.open('codesearch_py/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_queries)\n",
    "with jsonlines.open('codesearch_py/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_corpus)\n",
    "with open('codesearch_py/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in full_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small helper function to convert a string to a numeric value\n",
      "    if appropriate\n",
      "\n",
      "    :param s: the string to be converted\n",
      "    :type s: str\n",
      "def _convert_to_float_if_possible(s):\n",
      "    \n",
      "    rawurl = []\n",
      "    dom = parseString(xml_data)\n",
      "    for node in dom.getElementsByTagName('durl'):\n",
      "        url = node.getElementsByTagName('url')[0]\n",
      "        rawurl.append(url.childNodes[0].data)\n",
      "    return rawurl\n"
     ]
    }
   ],
   "source": [
    "print(python_short_descs[48][\"func_documentation_string\"] )\n",
    "print((python_short_descs[48][\"func_code_string\"].split('\"\"\"')[0] +  python_short_descs[0][\"func_code_string\"].split('\"\"\"')[2]).replace(\"\\n\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call the specified consumer with the current element passing through any 'rail'after it has been delivered to downstream within the rail.\n",
      "===\n",
      "@CheckReturnValue\n",
      "    @NonNull\n",
      "    public final ParallelFlowable<T> doAfterNext(@NonNull Consumer<? super T> onAfterNext) {\n",
      "        ObjectHelper.requireNonNull(onAfterNext, \"onAfterNext is null\");\n",
      "        return RxJavaPlugins.onAssembly(new ParallelPeek<T>(this,\n",
      "                Functions.emptyConsumer(),\n",
      "                onAfterNext,\n",
      "                Functions.emptyConsumer(),\n",
      "                Functions.EMPTY_ACTION,\n",
      "                Functions.EMPTY_ACTION,\n",
      "                Functions.emptyConsumer(),\n",
      "                Functions.EMPTY_LONG_CONSUMER,\n",
      "                Functions.EMPTY_ACTION\n",
      "                ));\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "print(java_short_descs[10][\"func_documentation_string\"].split(\"@param\")[0].replace(\"\\n\",\"\"))\n",
    "print(\"===\")\n",
    "print(java_short_descs[10][\"func_code_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16745"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(java_short_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412178\n"
     ]
    }
   ],
   "source": [
    "print(len(python_code_serach_net[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "454451it [01:27, 5216.35it/s]\n",
      "15328it [00:04, 3713.20it/s]\n",
      "26909it [00:05, 5356.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Code Search java\n",
    "full_corpus = []\n",
    "full_queries = []\n",
    "full_qrels = []\n",
    "answer2id = {}\n",
    "\n",
    "for idx, item in tqdm(enumerate(java_code_serach_net[\"train\"])):\n",
    "    doc_id = \"codeserachnet_javatrain_{0}_{1}\".format(idx, item[\"func_name\"])\n",
    "    code = item[\"func_code_string\"]\n",
    "    full_corpus.append({\"_id\": doc_id, \"text\": code, \"metadata\": {}, \"title\": \"\" })\n",
    "    answer2id[code]  =  doc_id\n",
    "\n",
    "for idx, item in tqdm(enumerate(java_code_serach_net[\"validation\"])):\n",
    "    doc_id = \"codeserachnet_java_validation_{0}_{1}\".format(idx, item[\"func_name\"])\n",
    "    code = item[\"func_code_string\"]\n",
    "    full_corpus.append({\"_id\": doc_id, \"text\": code, \"metadata\": {}, \"title\": \"\" })\n",
    "    answer2id[code]  =  doc_id\n",
    "\n",
    "for idx, item in tqdm(enumerate(java_code_serach_net[\"test\"])):\n",
    "    doc_id = \"codeserachnet_java_test_{0}_{1}\".format(idx, item[\"func_name\"])\n",
    "    code = item[\"func_code_string\"]\n",
    "    full_corpus.append({\"_id\": doc_id, \"text\": code, \"metadata\": {}, \"title\": \"\" })\n",
    "    answer2id[code]  =  doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(random_sampled_ja_short_descs):\n",
    "    qid = \"java_codesearch_{}\".format(idx)\n",
    "    \n",
    "    query = item[\"func_documentation_string\"].split(\"@param\")[0].replace(\"\\n\",\"\")\n",
    "    code = item[\"func_code_string\"]\n",
    "    corpus_id = answer2id[code]\n",
    "    full_queries.append({\"_id\": qid, \"text\": query, \"metadata\": {}})\n",
    "    full_qrels.append({\"corpus-id\": corpus_id, \"query-id\": qid, \"score\": 1})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"codesearch_ja/qrels\")\n",
    "with jsonlines.open('codesearch_ja/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_queries)\n",
    "with jsonlines.open('codesearch_ja/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_corpus)\n",
    "with open('codesearch_ja/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in full_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus.jsonl  qrels  queries.jsonl\n"
     ]
    }
   ],
   "source": [
    "! ls codesearch_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"_id\": \"java_codesearch_0\", \"text\": \"getter for semanticType - gets A semantic type, typically the name of an Entity Annotation type.@generated@return value of the feature\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_1\", \"text\": \"Create an instance of {@link JAXBElement }{@code <}{@link Calendar }{@code >}}\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_2\", \"text\": \"Sets the state of the next available flag and notifies any listeners of this change.\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_3\", \"text\": \"Sets the destination (method, host, port... ) at once.\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_4\", \"text\": \"Convert this multislice to a stringsuitable for use in a constraint@return constraint usable string@throws DapException\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_5\", \"text\": \"Rotates a 2D point by the specified angle.\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_6\", \"text\": \"Remove the non-cloudSearch-legal characters. Note that this might converttwo fields to the same name.@see <ahref=\\\"http://docs.aws.amazon.com/cloudsearch/latest/developerguide/configuring-index-fields.html\\\">configuring-index-fields.html</a>\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_7\", \"text\": \"Writes an array of bytes to the compressed output stream. Thismethod will block until all the bytes are written.\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_8\", \"text\": \"Key.create(Blah.class, name) is easier to type than new Key<Blah>(Blah.class, name)\", \"metadata\": {}}\n",
      "{\"_id\": \"java_codesearch_9\", \"text\": \"/*Publish the write state, storing the artifacts in the provided object. Visible for testing.\", \"metadata\": {}}\n"
     ]
    }
   ],
   "source": [
    "! head codesearch_ja/queries.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinkSO \n",
    "linkso_data_python = \"/private/home/akariasai/inst_dpr/preprocessing/linkso_data/topublish/python\"\n",
    "linkso_data_java = \"/private/home/akariasai/inst_dpr/preprocessing/linkso_data/topublish/java\"\n",
    "\n",
    "\n",
    "def find_duplicated_qestions(dir, lang):\n",
    "    full_corpus = []\n",
    "    full_queries = []\n",
    "    full_qrels = []\n",
    "    answer2id = {}\n",
    "    qid2all = pd.read_csv(os.path.join(dir, \"{}_qid2all.txt\".format(lang)), sep=\"\\t\", header=None)\n",
    "    qid2all_dic = {}\n",
    "    for idx, row in qid2all.iterrows():\n",
    "        full_corpus.append({\"_id\": \"linkso_{0}_{1}\".format(lang, row[0]), \"title\": row[1], \"text\": row[2] if row[3] is not None else row[1], \"metadata\": {}})\n",
    "        qid2all_dic[int(row[0])] = {\"title\": row[1], \"body\": row[2]}\n",
    "    \n",
    "\n",
    "    cosin =  pd.read_csv(os.path.join(dir, \"{}_cosidf.txt\".format(lang)), sep=\"\\t\")\n",
    "    dup_pair_ids = {}\n",
    "    for idx, row in cosin.iterrows():\n",
    "        if row[\"label\"] == 1:\n",
    "            dup_pair_ids[int(row[\"qid1\"])] = int(row[\"qid2\"])\n",
    "        \n",
    "    test_qs = open(os.path.join(dir, \"{}_test_qid.txt\".format(lang))).read().split(\"\\n\")[:-1]\n",
    "\n",
    "    for q_id in test_qs:\n",
    "        normalized_qid = \"linkso_{0}_{1}\".format(lang, q_id)\n",
    "        full_queries.append({\"_id\":normalized_qid , \"text\": qid2all_dic[int(q_id)][\"title\"], \"metadata\": {}})\n",
    "        if int(q_id) in dup_pair_ids:\n",
    "            dup_id = dup_pair_ids[int(q_id)]\n",
    "            normalized_dup_id = \"linkso_{0}_{1}\".format(lang, dup_id)\n",
    "            full_qrels.append({\"corpus-id\": normalized_dup_id, \"query-id\": normalized_qid, \"score\": 1})\n",
    "    return full_corpus, full_queries, full_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corpus, full_queries, full_qrels = find_duplicated_qestions(linkso_data_python, \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'linkso_python_27787264',\n",
       " 'title': 'pandas query throws error column name starts number ',\n",
       " 'text': 'trying perform query following dataframe works fine however column name starts number throws syntax error file line syntaxerror invalid syntax think problem related format string wondering correct way form query ',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'linkso_python_33949786',\n",
       " 'text': 'could use batch normalization tensorflow ',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid2queries = {item[\"_id\"]: item[\"text\"] for item in full_queries}\n",
    "qid2corpus = {item[\"_id\"]: item for item in full_corpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus-id': 'linkso_python_33992029',\n",
       " 'query-id': 'linkso_python_33949786',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qrels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'could use batch normalization tensorflow '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2queries['linkso_python_33949786']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'linkso_python_33992029',\n",
       " 'title': 'implementing batch normalization tensorflow ',\n",
       " 'text': 'trying implement batch normalization layer tensor flow problem running train step using tf moments get mean variance test time like set exponential moving average track mean variance trying like variable cpu defined believe setting incorrectly sure use tensorboard track mean variance variables flat initialized values ',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2corpus['linkso_python_33992029']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(\"linkso_py/qrels\")\n",
    "with jsonlines.open('linkso_py/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_queries)\n",
    "with jsonlines.open('linkso_py/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_corpus)\n",
    "with open('linkso_py/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in full_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corpus, full_queries, full_qrels = find_duplicated_qestions(linkso_data_java, \"java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"linkso_ja/qrels\")\n",
    "with jsonlines.open('linkso_ja/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_queries)\n",
    "with jsonlines.open('linkso_ja/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_corpus)\n",
    "with open('linkso_ja/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in full_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'linkso_java_8388608',\n",
       " 'title': 'java swing update component content independently ',\n",
       " 'text': 'could update content several visible one time components separately independently example would like show kind progress indicator connected information updated painted without painting components form one components progress must update content ',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus-id': 'linkso_java_8476588',\n",
       " 'query-id': 'linkso_java_2272169',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qrels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PubMed QA \n",
    "pubmed_labeled = json.load(open(\"/checkpoint/akariasai/datasets/pubmedqa/data/ori_pqal.json\"))\n",
    "pubmed_unlabeled = json.load(open(\"/checkpoint/akariasai/datasets/pubmedqa/data/ori_pqau.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pubmed_labeled.keys()) & set(pubmed_unlabeled.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corpus = []\n",
    "full_queries = []\n",
    "full_qrels = []\n",
    "answer2id = {}\n",
    "qid2passage = {}\n",
    "for qid, item in pubmed_labeled.items():\n",
    "    modified_qid = \"pubmedqa_labeled_{}_doc\".format(qid)\n",
    "    text = \" \".join(item[\"CONTEXTS\"]) + item[\"LONG_ANSWER\"]\n",
    "    full_corpus.append({\"_id\": modified_qid, \"text\": text, \"title\": \"\", \"metadata\": {}})\n",
    "\n",
    "for qid, item in pubmed_unlabeled.items():\n",
    "    modified_qid = \"pubmedqa_unlabeled_{}_doc\".format(qid)\n",
    "    text = \" \".join(item[\"CONTEXTS\"]) + item[\"LONG_ANSWER\"]\n",
    "    full_corpus.append({\"_id\": modified_qid, \"text\": text, \"title\": \"\", \"metadata\": {}})\n",
    "\n",
    "for qid, item in pubmed_labeled.items():\n",
    "    doc_id =  \"pubmedqa_labeled_{}_doc\".format(qid)\n",
    "    query_id = \"pubmedqa_labeled_{}_query\".format(qid)\n",
    "    full_queries.append({\"_id\":query_id, \"text\": item[\"QUESTION\"], \"metadata\": {}})\n",
    "    full_qrels.append({\"corpus-id\":doc_id, \"query-id\": query_id, \"score\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2corpus = {item[\"_id\"]: item for item in full_corpus}\n",
    "id2cquery= {item[\"_id\"]: item for item in full_queries}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corpus-id': 'pubmedqa_labeled_21645374_doc',\n",
       " 'query-id': 'pubmedqa_labeled_21645374_query',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qrels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'pubmedqa_labeled_21645374_doc',\n",
       " 'text': 'Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants. The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A. madagascariensis. A single areole within a window stage leaf (PCD is occurring) was divided into three areas based on the progression of PCD; cells that will not undergo PCD (NPCD), cells in early stages of PCD (EPCD), and cells in late stages of PCD (LPCD). Window stage leaves were stained with the mitochondrial dye MitoTracker Red CMXRos and examined. Mitochondrial dynamics were delineated into four categories (M1-M4) based on characteristics including distribution, motility, and membrane potential (ΔΨm). A TUNEL assay showed fragmented nDNA in a gradient over these mitochondrial stages. Chloroplasts and transvacuolar strands were also examined using live cell imaging. The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells.Results depicted mitochondrial dynamics in vivo as PCD progresses within the lace plant, and highlight the correlation of this organelle with other organelles during developmental PCD. To the best of our knowledge, this is the first report of mitochondria and chloroplasts moving on transvacuolar strands to form a ring structure surrounding the nucleus during developmental PCD. Also, for the first time, we have shown the feasibility for the use of CsA in a whole plant system. Overall, our findings implicate the mitochondria as playing a critical and early role in developmentally regulated PCD in the lace plant.',\n",
       " 'title': '',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2corpus['pubmedqa_labeled_21645374_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'pubmedqa_labeled_21645374_query',\n",
       " 'text': 'Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?',\n",
       " 'metadata': {}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2cquery[\"pubmedqa_labeled_21645374_query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Despite rapid adoption of the Hirsch index (h-index) as a measure of academic success, the correlations between the h-index and other metrics of productivity remain poorly understood. The aims of this study were to determine whether h-indices were associated with greater National Institutes of Health (NIH) funding success among academic radiologists. Using the Scopus database, h-indices were calculated for a random sample of academic radiologists with the rank of professor. Using the NIH tool Research Portfolio Online Reporting Tools Expenditures and Reports, we determined the number, classification, and total years of NIH grant funding as principal investigator for each radiologist. Differences in h-index, sorted by funding status, were determined using Wilcoxon's tests. Associations between h-index and funding status were determined using logistic regression. Significant correlations between h-index and grant metrics were determined using Spearman's ρ. Among 210 professors of radiology, 48 (23%) secured at least one NIH grant. The mean h-index was significantly higher among individuals who secured at least one NIH grant (19.1) compared to those who did not (10.4) (P<.0001). Professors with h-indices<10 compared to those with h-indices>10 were significantly less likely to receive NIH funding (odds ratio, 0.07; P = .0321). However, h-indices>10 were not significantly predictive of greater funding. No significant relationships were observed between h-index and the number of grant awards, years of prior funding, the amounts of grant awards, or grant classification.Having obtained at least one NIH grant was associated with a higher h-index, yet multiple or large grants, such as those for program projects, were not predictive of higher h-indices.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(pubmed_labeled[\"21873082\"][\"CONTEXTS\"]) + pubmed_labeled[\"21873082\"][\"LONG_ANSWER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"pubmedqa/qrels\")\n",
    "with jsonlines.open('pubmedqa/queries.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_queries)\n",
    "with jsonlines.open('pubmedqa/corpus.jsonl', 'w') as writer:\n",
    "    writer.write_all(full_corpus)\n",
    "with open('pubmedqa/qrels/test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['query-id', 'corpus-id', \"score\"])\n",
    "    for item in full_qrels:\n",
    "        tsv_writer.writerow([item[\"query-id\"], item[\"corpus-id\"], item[\"score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
